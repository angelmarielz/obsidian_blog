<!DOCTYPE html>
<html lang="en">
<head>
  
    <title> :: Terminal</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="an open-source orchestration library that helps developers connection LLMs for building complex applications_
![[Pasted image 202509117.png.webp]]
It provides a standard interface for various components and abstractions:
LLMs: The backbone of LangChain, LLMs like OpenAI’s GPT-3 or GPT-4 provide the core capabilities for understanding and generating language. They are trained on vast datasets to produce coherent and contextually relevant text. Prompt Templates: These templates structure the input to LLMs, maximizing their effectiveness in understanding and responding to queries. By designing effective prompts, developers can guide the LLMs to produce desired outputs. Output Parsers: These components refine the language generated by LLMs into formats that are useful and relevant to specific tasks, enhancing the overall user experience. Vector Store: This component handles the embedding of words or phrases into numerical vectors, which is essential for tasks involving semantic analysis and understanding language nuances. Agents: Agents are decision-making components that determine the best course of action based on input, context, and available resources. They enable LLMs to interact intelligently with their environment. Chain Chain of Thought (CoT), the implementation on minimum manageable steps
" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="/posts/20250606---langchain/" />





  
  <link rel="stylesheet" href="/css/buttons.min.86f6b4c106b6c6eb690ae5203d36b442c1f66f718ff4e8164fa86cf6c61ad641.css">

  
  <link rel="stylesheet" href="/css/code.min.d529ea4b2fb8d34328d7d31afc5466d5f7bc2f0bc9abdd98b69385335d7baee4.css">

  
  <link rel="stylesheet" href="/css/fonts.min.5bb7ed13e1d00d8ff39ea84af26737007eb5051b157b86fc24487c94f3dc8bbe.css">

  
  <link rel="stylesheet" href="/css/footer.min.eb8dfc2c6a7eafa36cd3ba92d63e69e849e2200e0002a228d137f236b09ecd75.css">

  
  <link rel="stylesheet" href="/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css">

  
  <link rel="stylesheet" href="/css/header.min.75c7eb0e2872d95ff48109c6647d0223a38db52e2561dd87966eb5fc7c6bdac6.css">

  
  <link rel="stylesheet" href="/css/main.min.775ac2af004d44c22a6d000fbd1d9af529642f5cef27399d0280d180af2c2e9b.css">

  
  <link rel="stylesheet" href="/css/menu.min.310d32205bdedd6f43144e3c3273c9deecd238eba5f9108db5ea96ca0cfbe377.css">

  
  <link rel="stylesheet" href="/css/pagination.min.bbb986dbce00a5ce5aca0504b7925fc1c581992a4bf57f163e5d69cc1db7d836.css">

  
  <link rel="stylesheet" href="/css/post.min.ad50c7f4d00e7975918f37fc74c6029e1959a40d66fb5b2c6564a8715e985573.css">

  
  <link rel="stylesheet" href="/css/syntax.min.e9ab635cf918bc84b901eb65c0b2caa74c9544245e3647c1af5c129896ef276e.css">

  
  <link rel="stylesheet" href="/css/terminal.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css">

  
  <link rel="stylesheet" href="/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css">







<link rel="shortcut icon" href="/favicon.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">


<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="">
<meta property="og:description" content="an open-source orchestration library that helps developers connection LLMs for building complex applications_
![[Pasted image 202509117.png.webp]]
It provides a standard interface for various components and abstractions:
LLMs: The backbone of LangChain, LLMs like OpenAI’s GPT-3 or GPT-4 provide the core capabilities for understanding and generating language. They are trained on vast datasets to produce coherent and contextually relevant text. Prompt Templates: These templates structure the input to LLMs, maximizing their effectiveness in understanding and responding to queries. By designing effective prompts, developers can guide the LLMs to produce desired outputs. Output Parsers: These components refine the language generated by LLMs into formats that are useful and relevant to specific tasks, enhancing the overall user experience. Vector Store: This component handles the embedding of words or phrases into numerical vectors, which is essential for tasks involving semantic analysis and understanding language nuances. Agents: Agents are decision-making components that determine the best course of action based on input, context, and available resources. They enable LLMs to interact intelligently with their environment. Chain Chain of Thought (CoT), the implementation on minimum manageable steps
" />
<meta property="og:url" content="/posts/20250606---langchain/" />
<meta property="og:site_name" content="Terminal" />

  <meta property="og:image" content="/og-image.png">

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">













</head>
<body>


<div class="container">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/showcase">Showcase</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/about" >About</a></li>
        
      
        
          <li><a href="/showcase" >Showcase</a></li>
        
      
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<article class="post">
  <h1 class="post-title">
    <a href="/posts/20250606---langchain/"></a>
  </h1>
  <div class="post-meta"></div>

  
  


  

  <div class="post-content"><div>
        <p>an open-source orchestration library that helps developers connection LLMs for building complex applications_</p>
<p>![[Pasted image 202509117.png.webp]]</p>
<p>It provides a standard interface for various components and abstractions:</p>
<ul>
<li><code>LLMs</code>: The backbone of LangChain, LLMs like OpenAI’s GPT-3 or GPT-4 provide the core capabilities for understanding and generating language. They are trained on vast datasets to produce coherent and contextually relevant text.</li>
<li><code>Prompt Templates</code>: These templates structure the input to LLMs, maximizing their effectiveness in understanding and responding to queries. By designing effective prompts, developers can guide the LLMs to produce desired outputs.</li>
<li><code>Output Parsers</code>: These components refine the language generated by LLMs into formats that are useful and relevant to specific tasks, enhancing the overall user experience.</li>
<li><code>Vector Store</code>: This component handles the embedding of words or phrases into numerical vectors, which is essential for tasks involving semantic analysis and understanding language nuances.</li>
<li><code>Agents</code><strong>:</strong> Agents are decision-making components that determine the best course of action based on input, context, and available resources. They enable LLMs to interact intelligently with their environment.</li>
</ul>
<h2 id="chain">Chain<a href="#chain" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<p>Chain of Thought (CoT), the implementation on minimum manageable steps</p>
<ul>
<li>explicitly guiding the LLM to think step-by-step through a problem</li>
<li>split the overall task into subtasks and run the subtasks sequentially</li>
<li>the output of one step becomes the input of the next</li>
</ul>
<p>![[Pasted image 202509118.png.webp]]</p>
<p><code>chain</code> <code>=</code> <code>prompt</code> <strong><code>|</code></strong> <code>model</code> <code>**|** outputParser</code></p>
<h1 id="langchain-ecosystem">LangChain Ecosystem<a href="#langchain-ecosystem" class="hanchor" ariaLabel="Anchor">#</a> </h1>
<p>!<img src="/images/Pasted%20image%20202509119.png.png" alt="Image Description"></p>
<h1 id="langgraph">LangGraph<a href="#langgraph" class="hanchor" ariaLabel="Anchor">#</a> </h1>
<p>LangGraph is an extension of LangChain that focuses on building more complex and controllable agent workflows using a graph-based approach</p>
<h2 id="langchain-vs-langgraph-dag-vs-graph">LangChain vs LangGraph (DAG vs Graph)<a href="#langchain-vs-langgraph-dag-vs-graph" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<p>!<img src="/images/Pasted%20image%202025091110.png.png" alt="Image Description"></p>
<p>Key components:</p>
<ul>
<li><code>State</code>: A shared data structure that represents the current snapshot of your application.</li>
<li><code>Nodes</code>: Python functions that encode the logic of your agents. They receive the current <code>State</code> as input, perform some computation or side-effect, and return an updated <code>State</code>.</li>
<li><code>Edges</code>: Python functions that determine which <code>Node</code> to execute next based on the current <code>State</code>. They can be conditional branches or fixed transitions.</li>
</ul>
<p>Support cases such as time travel/human in the loop/parallelization/multi agents(stateful) architecture</p>
<h2 id="deciding-between-langchain-and-openai-api">Deciding Between LangChain and OpenAI API<a href="#deciding-between-langchain-and-openai-api" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<h3 id="use-direct-api-such-as-openai-when">Use Direct API (such as OpenAI) When:<a href="#use-direct-api-such-as-openai-when" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<ul>
<li>
<p>Simplicity and performance are top priorities.</p>
</li>
<li>
<p>Tasks are straightforward and don’t require chaining operations.</p>
</li>
<li>
<p>Answering single-turn questions</p>
</li>
<li>
<p>Running one-off analyses</p>
</li>
<li>
<p>Performance-critical applications</p>
</li>
</ul>
<h3 id="use-langchain-when">Use LangChain When:<a href="#use-langchain-when" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<ul>
<li>
<p>You need to chain multiple operations conveniently.</p>
</li>
<li>
<p>Development speed and maintainability are important.</p>
</li>
<li>
<p>Your project involves integrating tools, external APIs, or maintaining state across interactions.</p>
</li>
<li>
<p>Ease of Chaining Tasks: You can easily combine multiple operations (e.g., answering questions based on external data).</p>
</li>
<li>
<p>Built-in Tools and Agents: LangChain offers agents to manage complex workflows with minimal code.</p>
</li>
<li>
<p>Extensibility: It integrates with external systems like document stores, APIs, and Python functions.</p>
</li>
</ul>
<h1 id="langsmith">LangSmith<a href="#langsmith" class="hanchor" ariaLabel="Anchor">#</a> </h1>
<p>![[Pasted image 2025091111.png.gif]]</p>
<h1 id="appendix">Appendix<a href="#appendix" class="hanchor" ariaLabel="Anchor">#</a> </h1>
<ul>
<li><a href="https://medium.com/@ab.hassanein/demystifying-langchain-tool-calling-agent-75cba2c46a61">https://medium.com/@ab.hassanein/demystifying-langchain-tool-calling-agent-75cba2c46a61</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/concepts/low_level/#graphs">https://langchain-ai.github.io/langgraph/concepts/low_level/#graphs</a></li>
<li><a href="https://blogs.adityabh.is-a.dev/posts/langchain-vs-openai-simplicity-vs-scalability/">https://blogs.adityabh.is-a.dev/posts/langchain-vs-openai-simplicity-vs-scalability/</a></li>
<li><a href="https://www.pinecone.io/learn/series/rag/rerankers/">https://www.pinecone.io/learn/series/rag/rerankers/</a></li>
</ul>
<p>!<img src="/images/Pasted%20image%202025091112.png" alt="Image Description"></p>

      </div></div>

  
    
<div class="pagination">
  <div class="pagination__title">
    <span class="pagination__title-h">Read other posts</span>
    <hr />
  </div>
  <div class="pagination__buttons">
    
      <a href="/posts/20250529---agentic-ai/" class="button inline prev">
        &lt; [<span class="button__text"></span>]
      </a>
    
    
      ::
    
    
      <a href="/posts/20250710---crewai/" class="button inline next">
         [<span class="button__text"></span>] &gt;
      </a>
    
  </div>
</div>


  

  
    

  
</article>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2025 Powered by <a href="https://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/bundle.min.js"></script>





  
</div>

</body>
</html>
