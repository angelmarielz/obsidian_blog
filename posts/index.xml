<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Terminal</title>
    <link>/posts/</link>
    <description>Recent content in Posts on Terminal</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Wed, 03 Sep 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MCP &amp; Vibe Coding</title>
      <link>/posts/mcp--vibe-coding/</link>
      <pubDate>Wed, 03 Sep 2025 00:00:00 +0000</pubDate>
      <guid>/posts/mcp--vibe-coding/</guid>
      <description>&lt;h2 id=&#34;general-mcp-work-flow&#34;&gt;General MCP work flow&lt;/h2&gt;&#xA;&lt;p&gt;!&lt;img src=&#34;/images/Pasted%20image%20202509041.png.png&#34; alt=&#34;Image Description&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;mcp-in-ide&#34;&gt;MCP in IDE&lt;/h2&gt;&#xA;&lt;p&gt;歡迎凱大跟子勤!&lt;/p&gt;&#xA;&lt;h3 id=&#34;ide&#34;&gt;IDE&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Claude &lt;a href=&#34;https://www.cursor.com/&#34;&gt;https://www.cursor.com/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Windsurf &lt;a href=&#34;https://windsurf.com/pricing&#34;&gt;https://windsurf.com/pricing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;TRAE &lt;a href=&#34;https://www.trae.ai/&#34;&gt;https://www.trae.ai/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;FireStudio &lt;a href=&#34;https://firestudio.space/&#34;&gt;https://firestudio.space/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;llm-model&#34;&gt;LLM Model&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Claude-3.7&lt;/li&gt;&#xA;&lt;li&gt;GPT-4o&lt;/li&gt;&#xA;&lt;li&gt;DeepSeek-V3&lt;/li&gt;&#xA;&lt;li&gt;Gemini-2.5 pro&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;!&lt;img src=&#34;/images/Pasted%20image%20202509042.png.png&#34; alt=&#34;Image Description&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;flow---ide-with-llm&#34;&gt;Flow - IDE with LLM&lt;/h2&gt;&#xA;&lt;p&gt;!&lt;img src=&#34;/images/Pasted%20image%20202509043.png.png&#34; alt=&#34;Image Description&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;flow---ide-with-llm-and-mcp&#34;&gt;Flow - IDE with LLM and MCP&lt;/h2&gt;&#xA;&lt;p&gt;!&lt;img src=&#34;/images/Pasted%20image%20202509045.png.png&#34; alt=&#34;Image Description&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;config-example-for-get-doc-content&#34;&gt;Config example for get doc content&lt;/h3&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/modelcontextprotocol/servers&#34;&gt;https://github.com/modelcontextprotocol/servers&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;{&lt;br&gt;&#xA;&amp;ldquo;mcpServers&amp;rdquo;: {&lt;br&gt;&#xA;&amp;ldquo;LarkDocs&amp;rdquo;: {&lt;br&gt;&#xA;&amp;ldquo;command&amp;rdquo;: &amp;ldquo;npx&amp;rdquo;,&lt;br&gt;&#xA;&amp;ldquo;args&amp;rdquo;: [&lt;br&gt;&#xA;&amp;ldquo;-y&amp;rdquo;,&lt;br&gt;&#xA;&amp;ldquo;&amp;ndash;registry&amp;rdquo;,&lt;br&gt;&#xA;&amp;ldquo;http://bnpm.byted.org/&amp;rdquo;,&lt;br&gt;&#xA;&amp;ldquo;@byted/mcp-lark-docs@latest&amp;rdquo;&lt;br&gt;&#xA;],&lt;br&gt;&#xA;&amp;ldquo;env&amp;rdquo;: {&lt;br&gt;&#xA;&amp;ldquo;LARK_APP_ID&amp;rdquo;: &amp;ldquo;ididid&amp;rdquo;,&lt;br&gt;&#xA;&amp;ldquo;LARK_APP_SECRET&amp;rdquo;: &amp;ldquo;secret&amp;rdquo;,&lt;br&gt;&#xA;&amp;ldquo;AUTH_CALLBACK_PORT&amp;rdquo;: &amp;ldquo;&amp;rdquo;,&lt;br&gt;&#xA;&amp;ldquo;AUTH_CALLBACK_ENDPOINT&amp;rdquo;: &amp;quot;&amp;quot;&lt;br&gt;&#xA;}&lt;br&gt;&#xA;}&lt;br&gt;&#xA;}&lt;br&gt;&#xA;}&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>/posts/agentic-ai/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/posts/agentic-ai/</guid>
      <description>&lt;h2 id=&#34;what-is-agents&#34;&gt;What is Agents?&lt;/h2&gt;&#xA;&lt;p&gt;AI Agents are programs where LLM outputs control the workflow. People often describes a solution as “AI Solution” that involves any of the following:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Multiple LLM calls&lt;/li&gt;&#xA;&lt;li&gt;LLMs with ability to use Tools&lt;/li&gt;&#xA;&lt;li&gt;An environment where LLMs interact with each other&lt;/li&gt;&#xA;&lt;li&gt;A planner to coordinate activities&lt;/li&gt;&#xA;&lt;li&gt;Autonomy&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;difference-between-workflow-and-agents&#34;&gt;Difference between Workflow and Agents&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Workflow - Systems where LLMs and tools are orchestrated through pre-defined code paths&lt;/li&gt;&#xA;&lt;li&gt;Agents - Systems where LLM dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;workflow-design-patterns&#34;&gt;Workflow Design Patterns&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Prompt Chaining&lt;/strong&gt;&lt;br&gt;&#xA;Use cases: Flows that could be divided. For example, split a long story into four episode and then translate them into different languages.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;!&lt;img src=&#34;/images/Pasted%20image%20202509111.png.png&#34; alt=&#34;Image Description&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>/posts/langchain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/posts/langchain/</guid>
      <description>&lt;p&gt;an open-source orchestration library that helps developers connection LLMs for building complex applications_&lt;/p&gt;&#xA;&lt;p&gt;![[Pasted image 202509117.png.webp]]&lt;/p&gt;&#xA;&lt;p&gt;It provides a standard interface for various components and abstractions:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;LLMs&lt;/code&gt;: The backbone of LangChain, LLMs like OpenAI’s GPT-3 or GPT-4 provide the core capabilities for understanding and generating language. They are trained on vast datasets to produce coherent and contextually relevant text.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Prompt Templates&lt;/code&gt;: These templates structure the input to LLMs, maximizing their effectiveness in understanding and responding to queries. By designing effective prompts, developers can guide the LLMs to produce desired outputs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Output Parsers&lt;/code&gt;: These components refine the language generated by LLMs into formats that are useful and relevant to specific tasks, enhancing the overall user experience.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Vector Store&lt;/code&gt;: This component handles the embedding of words or phrases into numerical vectors, which is essential for tasks involving semantic analysis and understanding language nuances.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Agents&lt;/code&gt;&lt;strong&gt;:&lt;/strong&gt; Agents are decision-making components that determine the best course of action based on input, context, and available resources. They enable LLMs to interact intelligently with their environment.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;chain&#34;&gt;Chain&lt;/h2&gt;&#xA;&lt;p&gt;Chain of Thought (CoT), the implementation on minimum manageable steps&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
